{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from mm.datasets import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>hospital</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.870661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.062477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.812503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  hospital   outcome\n",
       "0          0         3 -1.870661\n",
       "1          1         1  3.062477\n",
       "2          1         1  4.757326\n",
       "3          0         0  0.038551\n",
       "4          0         1  1.812503"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_data(5)\n",
    "df.treatment = df.treatment\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(x, shape=None, dtype=float):\n",
    "    t = torch.tensor(x).to(float)\n",
    "    if type(shape) != int and shape is not None:\n",
    "        shape = tuple(shape)\n",
    "    if shape is not None:\n",
    "        if t.shape != shape:\n",
    "            try:\n",
    "                t = t.reshape(shape)\n",
    "            except:\n",
    "                raise ValueError(f\"Cannot reshape {t.shape} to {shape}\")\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Model\n",
    "\n",
    "$Y \\sim N(X \\beta + o, \\sigma^2 W^{-1})$\n",
    "\n",
    "$(Y | B = b) \\sim N(X \\beta + Z b + o, \\sigma^2 W^{-1})$\n",
    "\n",
    "$B \\sim N(0, \\Sigma)$\n",
    "\n",
    "| name | shape | desc |\n",
    "| --- | --- | --- |\n",
    "| $X$ | $n \\times \\rho$ | fixed effect design matrix |\n",
    "| $\\beta$ | $\\rho \\times 1$ | fixed effect parameters |\n",
    "| $Z$ | $n \\times p$ | random effect design matrix |\n",
    "| $b$ | $p \\times 1$ | random effect parameters |\n",
    "| $o$ | $n \\times 1$ | prior offset terms |\n",
    "| $\\sigma^2$ | scalar | covariance scale parameter |\n",
    "| $W^{-1}$ | $n \\times n$ | covariance structure matrix |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem with this setup as stated is that $\\Sigma$, as a covariance matrix, must be nonsingular. We are going to be doing some kind of gradient descent over the elements in sigma though, and it would be convenient to not have to explicitly enforce this constraint during the optimization process. So, instead of modeling $B$ as a a normal with a given covariance, we model it as a linear transform of a unit-variance random variable $U$.\n",
    "\n",
    "$U \\sim N(0, \\sigma^2 I)$\n",
    "\n",
    "$B = \\Lambda_\\theta U$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$\\Sigma_\\theta = \\sigma^2 \\Lambda_\\theta \\Lambda_\\theta^T$\n",
    "\n",
    "We can then restate the model as,\n",
    "\n",
    "$\\mu_{y | U = u} = X \\beta + Z \\Lambda_\\theta u + o$\n",
    "\n",
    "$Y | U = N(\\mu_{y | U = u}, \\sigma^2 W^{-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deriving the matrix $Z$ involves a lot of index chasing, even though the idea is not that complicated. Basically, if we want to model the random effect of some variable $x$ with a grouping variable $g$, we have to split the $x$ column into a bunch of separate column, each corresponding to a unique value of $g$. For each of the columns, a cell will contain the corresponding unit's value of $x$ if and only if that column corresponds to the unit's value of $g$. Otherwise, it will be zero.\n",
    "\n",
    "The relative covariance factor $\\Lambda_\\theta$ will be a block diagonal matrix that specifies zero covariance between parameters for different groups. Inside each group, it will be a lower-diagonal matrix where each non-zero cell is a learnable parameter.\n",
    "\n",
    "- Are these learnable parameters different for each group? Idk\n",
    "\n",
    "It's important to allow correlation between random effect parameters inside each group because this makes the model invariant to additive shifts in the independent variable.\n",
    "\n",
    "- Why? Idk\n",
    "\n",
    "Note that both $Z$ and $\\Lambda$ are gonna be pretty sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Quest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider what our optimization problem is going to look like. We have distributions over both $y_{\\text{obs}}$ and $U$. Since they're both normal, the likelihoods are pretty stratiforward.\n",
    "\n",
    "Since $U$ has unit variance, $\\mathcal{L}(U = u) \\propto -||u||^2$.\n",
    "\n",
    "Similarly, $\\mathcal{L}(y = y_{\\text{obs}}) \\propto -||W^{1/2}[y_{\\text{obs}} - \\mu_{U = u}]||^2$.\n",
    "\n",
    "We are faced with the minimization problem\n",
    "\n",
    "$\\hat{u}, \\hat{\\beta} = \\underset{u, \\beta}{\\mathrm{argmin}} ( r^2 )$\n",
    "\n",
    "For\n",
    "\n",
    "$r^2 = ||W^{1/2}[y_{\\text{obs}} - \\mu_{U = u}]||^2 + ||u||^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that what we are trying to do here is just minimizing the squared length of the vector $\\rho^2$. This means that we can use the \"pseudo-data\" approach and think of this as an OLS problem. First, we rephrase it using matrix notation,\n",
    "\n",
    "$$\n",
    "r^2 =\n",
    "\\bigg|\\bigg|\n",
    "\\begin{bmatrix}\n",
    "W^{1/2}(y_{\\text{obs}} - o) \\\\\n",
    "0\n",
    "\\end{bmatrix} -\n",
    "\\begin{bmatrix}\n",
    "W^{1/2}Z\\Lambda_\\theta & W^{1/2}X \\\\\n",
    "I & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "u \\\\ b\n",
    "\\end{bmatrix}\n",
    "\\bigg|\\bigg|^2\n",
    "$$\n",
    "\n",
    "The top row of blocks is finding the penalty for $y_{\\text{obs}}$, and the bottom row is finding the penalty for $u$. One the left side of the difference, we have the means of the two distributions, and on the right side, we have the values conjectured by our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(somehow? by GLS?) We determine that the parameters of best fit are given by\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\Lambda_\\theta^T Z^T W (y_{\\text{obs}} - o)\\\\\n",
    "X^T W (y_{\\text{obs}} - o)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\Lambda_\\theta^T Z^T W Z \\Lambda_\\theta + I & \\Lambda_\\theta^T Z^T W X \\\\\n",
    "(\\Lambda_\\theta^T Z^T W X)^T & X^T W X\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\mu_{U | y = y_{\\text{obs}}} \\\\\n",
    "\\hat{\\beta_\\theta}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can cholesky decompose this bad boy.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\Lambda_\\theta^T Z^T W Z \\Lambda_\\theta + I & \\Lambda_\\theta^T Z^T W X \\\\\n",
    "(\\Lambda_\\theta^T Z^T W X)^T & X^T W X\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "L_\\theta & 0 \\\\\n",
    "R^T_{ZX} & R^T_X\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "L^T_\\theta & R_{ZX} \\\\\n",
    "0 & R_X\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apparently,\n",
    "\n",
    "$$\n",
    "r^2 = \\text{min}(r^2) +\n",
    "||\n",
    "L^T_\\theta (u - \\mu_{U | y = y_{\\text{obs}}}) +\n",
    "R_{ZX} (\\beta - \\hat{\\beta_\\theta})\n",
    "||^2 +\n",
    "|| R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "$$\n",
    "\n",
    "Which is apparently useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving for Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the assumptions of the model, we have,\n",
    "\n",
    "$$\n",
    "f_{y | U}(y_{\\text{obs}} | u) =\n",
    "{|W|^{1/2} \\over (2 \\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg( {\n",
    "    -||W^{1/2}(y_{\\text{obs}} - \\mu_{y | U = u})||^2 \\over\n",
    "    2 \\sigma^2\n",
    "} \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_U(u) = {1 \\over (2 \\pi \\sigma^2)^{q/2}}\n",
    "\\exp \\bigg({\n",
    "    -||u||^2 \\over 2\\sigma^2\n",
    "}\\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us,\n",
    "\n",
    "$$\n",
    "f_{y, U}(y_{\\text{obs}}, u) = f_{y | U}(y_{\\text{obs}} | u) f_U(u) =\n",
    "{|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "\\exp \\bigg(\n",
    "    {-r^2 \\over 2\\sigma^2}\n",
    "\\bigg)\n",
    "$$\n",
    "\n",
    "From which we can derive,\n",
    "\n",
    "$$\n",
    "f_y{y_{\\text{obs}}} = \\int f_{y, U}(y_{\\text{obs}}, u) du\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_{U | y}(u | y_{\\text{obs}}) = {f_{y, U}(y_{\\text{obs}}, u) \\over f_y{y_{\\text{obs}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal distribution of $y$ is what we care about. We can expand and factor out the $u$ terms.\n",
    "\n",
    "$f_y(y_{\\text{obs}})$\n",
    "\n",
    "$= \\int f_{y, U}(y_{\\text{obs}}, u) du$\n",
    "\n",
    "$\n",
    "= \\int\n",
    "    {|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "    \\exp \\bigg(\n",
    "        {-r^2 \\over 2\\sigma^2}\n",
    "    \\bigg)\n",
    "du\n",
    "$\n",
    "\n",
    "$\n",
    "= \\int\n",
    "    {|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "    \\exp \\bigg(\n",
    "        {\n",
    "            -(\\text{min}(r^2) +\n",
    "            ||\n",
    "            L^T_\\theta (u - \\mu_{U | y = y_{\\text{obs}}}) +\n",
    "            R_{ZX} (\\beta - \\hat{\\beta_\\theta})\n",
    "            ||^2 +\n",
    "            || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2)\n",
    "            \\over\n",
    "            2\\sigma^2\n",
    "        }\n",
    "    \\bigg)\n",
    "du\n",
    "$\n",
    "\n",
    "$\n",
    "= \\int\n",
    "    {|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "    \\exp \\bigg(\n",
    "        {\n",
    "            - \\text{min}(r^2)\n",
    "            - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "            \\over\n",
    "            2\\sigma^2\n",
    "        }\n",
    "    \\bigg)\n",
    "    \\exp \\bigg(\n",
    "        {\n",
    "            -\n",
    "            ||\n",
    "            L^T_\\theta (u - \\mu_{U | y = y_{\\text{obs}}}) +\n",
    "            R_{ZX} (\\beta - \\hat{\\beta_\\theta})\n",
    "            ||^2\n",
    "            \\over\n",
    "            2\\sigma^2\n",
    "        }\n",
    "    \\bigg)\n",
    "du\n",
    "$\n",
    "\n",
    "$= {|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\int\n",
    "    \\exp \\bigg(\n",
    "        {\n",
    "            -\n",
    "            ||\n",
    "            L^T_\\theta (u - \\mu_{U | y = y_{\\text{obs}}}) +\n",
    "            R_{ZX} (\\beta - \\hat{\\beta_\\theta})\n",
    "            ||^2\n",
    "            \\over\n",
    "            2\\sigma^2\n",
    "        }\n",
    "    \\bigg)\n",
    "du\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now let,\n",
    "\n",
    "$v = L^T_\\theta (u - \\mu_{U | y = y_{\\text{obs}}}) + R_{ZX} (\\beta - \\hat{\\beta_\\theta})$\n",
    "\n",
    "And then, via change of variables, the integral becomes,\n",
    "\n",
    "$= {|W|^{1/2} \\over (2\\pi \\sigma^2)^{(n + q)/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\int\n",
    "    \\exp \\bigg(\n",
    "        {- || v ||^2 \\over 2\\sigma^2}\n",
    "    \\bigg)\n",
    "    |L_\\theta|^{-1}\n",
    "dv\n",
    "$\n",
    "\n",
    "Which is apparently equal to,\n",
    "\n",
    "$= {|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\beta, \\sigma^2 | y_{\\text{obs}}) = \\log f_y (y_{\\text{obs}})\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$\n",
    "-2\\mathcal{L}(\\theta, \\beta, \\sigma^2 | y_{\\text{obs}}) = -2\\log f_y (y_{\\text{obs}})\n",
    "$\n",
    "\n",
    "$\n",
    "= -2\\log(\n",
    "    {|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "    \\exp \\bigg(\n",
    "        {\n",
    "            - \\text{min}(r^2)\n",
    "            - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "            \\over\n",
    "            2\\sigma^2\n",
    "        }\n",
    "    \\bigg)\n",
    ")\n",
    "$\n",
    "\n",
    "$\n",
    "= -2\\log({|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}})\n",
    "-2 {\n",
    "    - \\text{min}(r^2)\n",
    "    - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "    \\over\n",
    "    2\\sigma^2}\n",
    "$\n",
    "\n",
    "$\n",
    "= -2\\log(|W|^{1/2} |L_\\theta|^{-1}) + 2 \\log((2\\pi \\sigma^2)^{n/2})\n",
    "-2 {\n",
    "    - \\text{min}(r^2)\n",
    "    - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "    \\over\n",
    "    2\\sigma^2}\n",
    "$\n",
    "\n",
    "$\n",
    "= \\log({|L_\\theta|^{-1} \\over |W|}) + n \\log(2\\pi \\sigma^2) + {\n",
    "    \\text{min}(r^2)\n",
    "    \\over\n",
    "    \\sigma^2\n",
    "} - {\n",
    "|| R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "    \\over\n",
    "    \\sigma^2\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the maximum likelihood solution, we just minimize this. We can first minimize with respect to $\\beta$ by noticing that the only term containing $\\beta$ is minimized when $\\beta = \\hat{\\beta_\\theta}$, yielding,\n",
    "\n",
    "$\n",
    "\\log({|L_\\theta|^{-1} \\over |W|}) + n \\log(2\\pi \\sigma^2) + {\n",
    "    \\text{min}(r^2)\n",
    "    \\over\n",
    "    \\sigma^2\n",
    "}\n",
    "$\n",
    "\n",
    "We then take the derivative with respect to $\\sigma^2$ and set the result to zero.\n",
    "\n",
    "$\n",
    "{n \\over \\hat{\\sigma}^2} + {\n",
    "    \\text{min}(r^2)\n",
    "    \\over\n",
    "    \\hat{\\sigma}^4\n",
    "} = 0\n",
    "$\n",
    "\n",
    "$\n",
    "\\hat{\\sigma}^2 = {\\text{min}(r^2) \\over n}\n",
    "$\n",
    "\n",
    "This result in the likelihood,\n",
    "\n",
    "$\n",
    "\\log({|L_\\theta|^{-1} \\over |W|}) + n \\log(2\\pi {\\text{min}(r^2) \\over n}) + {\n",
    "    \\text{min}(r^2)n\n",
    "    \\over\n",
    "    \\text{min}(r^2)\n",
    "}\n",
    "$\n",
    "\n",
    "$\n",
    "= \\log({|L_\\theta|^{-1} \\over |W|}) + n \\big[ \\log(2\\pi {\\text{min}(r^2) \\over n}) + 1 \\big]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Maximum Likelihood Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\int f_y(y) d\\beta = \\int\n",
    "{|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "d\\beta\n",
    "$\n",
    "\n",
    "$\n",
    "= \\int\n",
    "{|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "d\\beta\n",
    "$\n",
    "\n",
    "$\n",
    "= {|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\int\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - || R_X(\\beta - \\hat{\\beta_\\theta}) ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "d\\beta\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let,\n",
    "\n",
    "$v = R_X(\\beta - \\hat{\\beta_\\theta})$\n",
    "\n",
    "For this, the jacobian determinant is $|R_X|$. Substituting into the above, we see that,\n",
    "\n",
    "$\n",
    "\\int f_y(y) d\\beta\n",
    "= {|W|^{1/2} |L_\\theta|^{-1} \\over (2\\pi \\sigma^2)^{n/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\int\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - || v ||^2\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "|R_X|^{-1}\n",
    "dv\n",
    "$\n",
    "\n",
    "$\n",
    "= {|W|^{1/2} |L_\\theta|^{-1} |R_X|^{-1} \\over (2\\pi \\sigma^2)^{(n - p)/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let,\n",
    "\n",
    "$\n",
    "-2 \\mathcal{L}_R = -2 \\log \\big( \\int f_y(y) d\\beta \\big)\n",
    "$\n",
    "\n",
    "Then,\n",
    "\n",
    "$\n",
    "= -2 \\log \\bigg[ {|W|^{1/2} |L_\\theta|^{-1} |R_X|^{-1} \\over (2\\pi \\sigma^2)^{(n - p)/2}}\n",
    "\\exp \\bigg(\n",
    "    {\n",
    "        - \\text{min}(r^2)\n",
    "        \\over\n",
    "        2\\sigma^2\n",
    "    }\n",
    "\\bigg)\n",
    "\\bigg]\n",
    "$\n",
    "\n",
    "$\n",
    "= -2 \\log \\bigg[ |W|^{1/2} |L_\\theta|^{-1} |R_X|^{-1} \\bigg] +\n",
    "2 \\log((2\\pi \\sigma^2)^{(n - p)/2}) - 2 {\n",
    "    - \\text{min}(r^2)\n",
    "    \\over\n",
    "    2\\sigma^2\n",
    "}\n",
    "$\n",
    "\n",
    "$\n",
    "= \\log \\bigg({|L_\\theta|^2 |R_X|^2 \\over |W|} \\bigg) +\n",
    "(n - p) \\log(2\\pi \\sigma^2) + {\n",
    "    \\text{min}(r^2)\n",
    "    \\over\n",
    "    \\sigma^2\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that\n",
    "\n",
    "- steps?\n",
    "\n",
    "$\n",
    "\\hat{\\sigma^2_\\theta} = {\\min(r^2) \\over n - p}\n",
    "$\n",
    "\n",
    "If a estimate for $\\beta$ is required, it's possible to find it using maximum likelihood while fixing the value of $\\theta$ to the REML estimate. This is kind of ad hoc, but it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in the final likelihood,\n",
    "\n",
    "$\n",
    "-2 \\mathcal{L}_R\n",
    "= \\log \\bigg({|L_\\theta|^2 |R_X|^2 \\over |W|} \\bigg) +\n",
    "(n - p) \\log(2\\pi {\\min(r^2) \\over n - p}) + {\n",
    "    \\text{min}(r^2)\n",
    "    \\over\n",
    "    \\big( {\\min(r^2) \\over n - p} \\big)\n",
    "}\n",
    "$\n",
    "\n",
    "$\n",
    "-2 \\mathcal{L}_R\n",
    "= \\log \\bigg({|L_\\theta|^2 |R_X|^2 \\over |W|} \\bigg) +\n",
    "(n - p) \\log(2\\pi {\\min(r^2) \\over n - p}) + (n - p)\n",
    "$\n",
    "\n",
    "$\n",
    "-2 \\mathcal{L}_R\n",
    "= \\log \\bigg({|L_\\theta|^2 |R_X|^2 \\over |W|} \\bigg) +\n",
    "(n - p) \\big( \\log(2\\pi {\\min(r^2) \\over n - p}) + 1 \\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = \"outcome\"\n",
    "fe_vars = [\"treatment\"]\n",
    "re_vars = [\"hospital\"]\n",
    "\n",
    "n = df.shape[0] # number of observations\n",
    "k = 1 # number of random effect terms in formula\n",
    "f = 1 # number of fixed effect terms\n",
    "\n",
    "l = df[re_vars].drop_duplicates().shape[0] # number of groups\n",
    "p = 1 # number of effects per group\n",
    "q = p * l # number of re parameters\n",
    "m = int((p + 1) * p / 2) # number of covariance parameters\n",
    "\n",
    "y = tensor(df.outcome.values, (n, 1))\n",
    "X = tensor(df[fe_vars].values, (n, f))\n",
    "o = torch.zeros_like(y)\n",
    "W = torch.eye(len(y)).to(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/zjyw1l0d37x3lbbq6x4vvs_00000gn/T/ipykernel_10037/3172120815.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(x).to(float)\n"
     ]
    }
   ],
   "source": [
    "class RandomEffect:\n",
    "    group_id_col_name = \"RE_GROUP_ID\"\n",
    "    def __init__(self, df, effects, groups):\n",
    "        self.effects = effects\n",
    "        self.groups = groups\n",
    "\n",
    "        # create group indicator matrix\n",
    "        self.group_df = (df[self.groups]\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "            .reset_index(names=RandomEffect.group_id_col_name))\n",
    "        \n",
    "        self.all_levels = tensor(self.group_df[RandomEffect.group_id_col_name].values, l)\n",
    "        self.df_levels = tensor(\n",
    "            pd.merge(df[groups], self.group_df, on=self.groups, how=\"left\")\n",
    "            [RandomEffect.group_id_col_name]\n",
    "            .values,\n",
    "            (n, 1)\n",
    "        )\n",
    "        assert not torch.any(torch.isnan(self.df_levels))\n",
    "        \n",
    "        self.df_levels_indicator_matrix = tensor(pd.get_dummies(self.df_levels.reshape(-1)).values, (n, l))\n",
    "\n",
    "        # create design matrix\n",
    "        effect_dm = {\n",
    "            effect:\n",
    "                self.df_levels_indicator_matrix if effect == 1\n",
    "                else self.df_levels_indicator_matrix * tensor(df[effect].values, (n, 1))\n",
    "            for effect in self.effects\n",
    "            }\n",
    "        \n",
    "        self.dm = tensor(torch.hstack([dm.T for dm in effect_dm.values()]).reshape(-1, n).T, (n, q))\n",
    "\n",
    "        # create covariance parameters\n",
    "        self.cv_params = torch.randn(m)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return (self.l, self.groups, self.effects) < (other.l, other.groups, other.effects)\n",
    "    \n",
    "    def relative_covariance_factor(self):\n",
    "        cv_template = torch.zeros(p, p)\n",
    "        cv_template[*torch.tril_indices(p, p)] = self.cv_params\n",
    "        cv = torch.block_diag(*(l*[cv_template]))\n",
    "        return tensor(cv, (q, q))\n",
    "\n",
    "re = RandomEffect(df, effects=[1], groups=[\"hospital\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/zjyw1l0d37x3lbbq6x4vvs_00000gn/T/ipykernel_10037/3172120815.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(x).to(float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [-0.5772],\n",
       "        [ 0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf = re.relative_covariance_factor()\n",
    "\n",
    "L = torch.linalg.cholesky((rcf.T @ re.dm.T @ W @ re.dm @ rcf) + torch.eye(rcf.shape[0]).to(float))\n",
    "cu = torch.linalg.solve(L, torch.linalg.solve(L, rcf @ re.dm.T @ W @ y))\n",
    "R_zx = torch.linalg.solve(L, torch.linalg.solve(L, rcf @ re.dm.T @ W @ X))\n",
    "RXtRX = X.T @ W @ X - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 12,  4, 16,  8, 20],\n",
       "        [ 1, 13,  5, 17,  9, 21],\n",
       "        [ 2, 14,  6, 18, 10, 22],\n",
       "        [ 3, 15,  7, 19, 11, 23]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = torch.arange(12).reshape(3, 4).T\n",
    "bar = torch.arange(12).reshape(3, 4).T + 12\n",
    "\n",
    "torch.hstack([foo.T, bar.T]).reshape(-1, 4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.eye(n)\n",
    "o = np.ones(n).reshape(-1, 1)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
